#!/usr/bin/env python3
"""
Stage 1: –î–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏
–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –æ–±—Å—É–∂–¥–∞–ª–∞—Å—å –ª–∏ –¥–æ—Å—Ç–∞–≤–∫–∞ –≤ –∫–∞–∂–¥–æ–º –¥–∏–∞–ª–æ–≥–µ
"""

import json
import logging
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from tenacity import retry, stop_after_attempt, wait_exponential
from typing import List, Dict, Any

import sys
sys.path.append(str(Path(__file__).parent.parent))

import openai
from config import settings
from models.validation import DeliveryDetection
from prompts import DELIVERY_DETECTION_PROMPT, STAGE_CONFIG

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI
if settings.openai_api_key:
    openai.api_key = settings.openai_api_key


@retry(
    stop=stop_after_attempt(settings.max_retries),
    wait=wait_exponential(multiplier=settings.retry_backoff_sec)
)
def second_pass_determine(text: str) -> bool:
    """–í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏ –≤ —Å–µ—Ä–æ–π –∑–æ–Ω–µ"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=settings.openai_api_key)
        
        # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞
        strict_prompt = """
        –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –¥–∏–∞–ª–æ–≥. –û–ø—Ä–µ–¥–µ–ª–∏ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —á–µ—Ç–∫–æ –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è –¥–æ—Å—Ç–∞–≤–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤.
        
        –ö—Ä–∏—Ç–µ—Ä–∏–∏ (–≤—Å–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω—ã):
        1. –ï—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥–æ—Å—Ç–∞–≤–∫–∏, –ü–í–ó, –∫—É—Ä—å–µ—Ä–∞, —Å–∞–º–æ–≤—ã–≤–æ–∑–∞
        2. –û–±—Å—É–∂–¥–∞–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
        3. –ï—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–ª—É—á–µ–Ω–∏–µ–º –∑–∞–∫–∞–∑–∞
        
        –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω - –æ—Ç–≤–µ—á–∞–π false.
        
        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {"delivery_discussed": true/false, "p_deliv": 0.0-1.0}
        """
        
        response = client.chat.completions.create(
            model=settings.openai_model,
            messages=[
                {"role": "system", "content": strict_prompt},
                {"role": "user", "content": f"–î–∏–∞–ª–æ–≥:\n{text}"}
            ],
            temperature=0.0,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
            max_tokens=100
        )
        
        content = response.choices[0].message.content
        
        if not content or not content.strip():
            return False
        
        # –û—á–∏—â–∞–µ–º JSON –æ—Ç markdown –±–ª–æ–∫–æ–≤
        cleaned_content = content.strip()
        if cleaned_content.startswith("```json"):
            cleaned_content = cleaned_content[7:]
        if cleaned_content.endswith("```"):
            cleaned_content = cleaned_content[:-3]
        cleaned_content = cleaned_content.strip()
        
        try:
            result = json.loads(cleaned_content)
            return result.get("delivery_discussed", False)
        except json.JSONDecodeError:
            return False
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞: {e}")
        return False


def detect_delivery_openai(text: str) -> Dict[str, Any]:
    """–î–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏ —á–µ—Ä–µ–∑ OpenAI API —Å —É–∂–µ—Å—Ç–æ—á–µ–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–æ–º"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=settings.openai_api_key)
        
        response = client.chat.completions.create(
            model=settings.openai_model,
            messages=[
                {"role": "system", "content": DELIVERY_DETECTION_PROMPT},
                {"role": "user", "content": f"–î–∏–∞–ª–æ–≥:\n{text}"}
            ],
            temperature=0.1,
            max_tokens=200
        )
        
        content = response.choices[0].message.content
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
        if not content or not content.strip():
            logger.warning(f"–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI –¥–ª—è –¥–∏–∞–ª–æ–≥–∞")
            return {"delivery_discussed": False, "p_deliv": 0.0}
        
        # –û—á–∏—â–∞–µ–º JSON –æ—Ç markdown –±–ª–æ–∫–æ–≤
        cleaned_content = content.strip()
        if cleaned_content.startswith("```json"):
            cleaned_content = cleaned_content[7:]  # –£–±–∏—Ä–∞–µ–º ```json
        if cleaned_content.endswith("```"):
            cleaned_content = cleaned_content[:-3]  # –£–±–∏—Ä–∞–µ–º ```
        cleaned_content = cleaned_content.strip()
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å JSON
        try:
            result = json.loads(cleaned_content)
            p_deliv = result.get("p_deliv", 0.0)
            THRESH = settings.delivery_conf_threshold
            
            # –£–∂–µ—Å—Ç–æ—á–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä
            if p_deliv >= THRESH:
                delivery_discussed = True
            elif p_deliv <= (1 - THRESH):
                delivery_discussed = False
            else:
                # –°–µ—Ä–∞—è –∑–æ–Ω–∞ - –≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥
                delivery_discussed = second_pass_determine(text)
                p_deliv = 0.8 if delivery_discussed else 0.2
            
            return {
                "delivery_discussed": delivery_discussed,
                "p_deliv": p_deliv
            }
            
        except json.JSONDecodeError as json_err:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {json_err}. –û—Ç–≤–µ—Ç: {cleaned_content[:200]}...")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è
            return {"delivery_discussed": False, "p_deliv": 0.0}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ OpenAI API: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è
        return {"delivery_discussed": False, "p_deliv": 0.0}


def detect_delivery_simple(text: str) -> Dict[str, Any]:
    """–ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    delivery_keywords = [
        "–¥–æ—Å—Ç–∞–≤–∫–∞", "–ø–≤–∑", "–ø—É–Ω–∫—Ç –≤—ã–¥–∞—á–∏", "–∫—É—Ä—å–µ—Ä", "–æ—Ç–ø—Ä–∞–≤–∏—Ç—å", "–ø—Ä–∏–≤–µ–∑—Ç–∏",
        "–∑–∞–±—Ä–∞—Ç—å", "–ª–æ–≥–∏—Å—Ç–∏–∫–∞", "–æ—Ç–ø—Ä–∞–≤–∫–∞", "–ø–æ—Å—Ç–∞–º–∞—Ç", "—Å–∞–º–æ–≤—ã–≤–æ–∑"
    ]
    
    text_lower = text.lower()
    mentions = sum(1 for keyword in delivery_keywords if keyword in text_lower)
    
    delivery_discussed = mentions > 0
    p_deliv = min(mentions / 5.0, 1.0)  # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
    
    return {
        "delivery_discussed": delivery_discussed,
        "p_deliv": p_deliv
    }


def process_dialog_batch(dialogs: List[Dict[str, Any]]) -> List[DeliveryDetection]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –¥–∏–∞–ª–æ–≥–æ–≤"""
    results = []
    
    for dialog in dialogs:
        try:
            dialog_id = str(dialog[settings.col_id])
            text = str(dialog[settings.col_text])
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏
            if settings.use_openai and settings.openai_api_key:
                detection = detect_delivery_openai(text)
            else:
                detection = detect_delivery_simple(text)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = DeliveryDetection(
                dialog_id=dialog_id,
                delivery_discussed=detection["delivery_discussed"],
                p_deliv=detection["p_deliv"]
            )
            
            results.append(result)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–∞ {dialog.get(settings.col_id, 'unknown')}: {e}")
            continue
    
    return results


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Stage 1"""
    logger.info("üöÄ Stage 1: –î–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ artifacts
    artifacts_dir = Path("artifacts")
    artifacts_dir.mkdir(exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info(f"üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {settings.xlsx_path}")
    try:
        df = pd.read_excel(settings.xlsx_path)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –¥–∏–∞–ª–æ–≥–æ–≤")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏
    results = []
    total_dialogs = len(df)
    
    logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {total_dialogs} –¥–∏–∞–ª–æ–≥–æ–≤ –±–∞—Ç—á–∞–º–∏ –ø–æ {settings.batch_size}")
    
    for i in tqdm(range(0, total_dialogs, settings.batch_size), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–µ–π"):
        batch_df = df.iloc[i:i + settings.batch_size]
        batch_dialogs = batch_df.to_dict('records')
        
        batch_results = process_dialog_batch(batch_dialogs)
        results.extend(batch_results)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = artifacts_dir / "stage1_delivery.jsonl"
    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {output_file}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result.dict()) + '\n')
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    delivery_count = sum(1 for r in results if r.delivery_discussed)
    avg_confidence = sum(r.p_deliv for r in results) / len(results) if results else 0
    delivery_percentage = (delivery_count / len(results) * 100) if results else 0
    
    logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Stage 1:")
    logger.info(f"  –í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {len(results)}")
    logger.info(f"  –° –¥–æ—Å—Ç–∞–≤–∫–æ–π: {delivery_count} ({delivery_percentage:.1f}%)")
    logger.info(f"  –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f}")
    
    logger.info("‚úÖ Stage 1 –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    main()
