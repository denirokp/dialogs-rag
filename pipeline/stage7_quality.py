#!/usr/bin/env python3
"""
Stage 7: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ reports/quality.json
"""

import json
import statistics
import logging
from pathlib import Path
from typing import Dict, Any

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from config import settings

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def compute_quality(aggregate_path: str = "artifacts/aggregate_results.json", out: str = "reports/quality.json") -> Dict[str, Any]:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    logger.info("üîç –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    agg = json.loads(Path(aggregate_path).read_text(encoding="utf-8"))
    N = agg["meta"]["N"]
    D = agg["meta"]["D"]

    # –û—Ü–µ–Ω–∏–º –Ω–∞ —É—Ä–æ–≤–Ω–µ raw (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏–ª–∏ –ø–æ –∞–≥—Ä–µ–≥–∞—Ç–∞–º
    clusters = agg.get("barriers", []) + agg.get("ideas", []) + agg.get("signals", []) + agg.get("signals_platform", [])
    clusters_count = len(clusters)
    mentions = [c["mentions_abs"] for c in clusters] or [0]
    avg_mentions = statistics.mean(mentions)

    # –ï—Å–ª–∏ –µ—Å—Ç—å stage1.5/2 –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã ‚Äî –ø–æ–¥—Ç—è–Ω–∏:
    valid_rate = None
    try:
        s15_path = Path("artifacts/stage1_5_sampling.jsonl")
        if s15_path.exists():
            s15 = [json.loads(l) for l in s15_path.read_text(encoding="utf-8").splitlines()]
            valid_samples = sum(1 for x in s15 if x.get("valid_sample"))
            valid_rate = (valid_samples / D) if D else 0.0
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å stage1.5 –¥–∞–Ω–Ω—ã–µ: {e}")

    no_entities_rate = None
    avg_quotes_per_cluster = None
    try:
        s2_path = Path("artifacts/stage2_extracted.jsonl")
        if s2_path.exists():
            s2 = [json.loads(l) for l in s2_path.read_text(encoding="utf-8").splitlines()]
            no_entities = sum(1 for x in s2 if x.get("delivery_discussed") and not (x.get("barriers") or x.get("ideas") or x.get("signals")))
            no_entities_rate = (no_entities / D) if D else 0.0
            
            quotes_per_cluster = []
            for c in clusters:
                quotes_per_cluster.append(len(c.get("quotes", [])))
            avg_quotes_per_cluster = statistics.mean(quotes_per_cluster) if quotes_per_cluster else 0.0
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å stage2 –¥–∞–Ω–Ω—ã–µ: {e}")

    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_quotes = sum(len(c.get("quotes", [])) for c in clusters)
    clusters_with_quotes = sum(1 for c in clusters if c.get("quotes"))
    dialogs_with_quotes = sum(1 for c in clusters if (c.get("quotes") or []))
    low_evidence_clusters = sum(1 for c in clusters if c.get("low_evidence_share", 0) >= 0.5)
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    barriers_count = len(agg.get("barriers", []))
    ideas_count = len(agg.get("ideas", []))
    signals_count = len(agg.get("signals", []))
    signals_platform_count = len(agg.get("signals_platform", []))

    out_data = {
        "N": N,
        "D": D, 
        "D_share": round((D/N), 3) if N else 0.0,
        "valid_rate": round(valid_rate, 3),
        "no_entities_rate": round(no_entities_rate, 3),
        "clusters_count": clusters_count,
        "avg_mentions_per_cluster": round(avg_mentions, 2),
        "avg_quotes_per_cluster": round(avg_quotes_per_cluster, 2) if avg_quotes_per_cluster is not None else None,
        "total_quotes": total_quotes,
        "clusters_with_quotes": clusters_with_quotes,
        "quotes_coverage": round((dialogs_with_quotes / (D or 1)), 3),
        "low_evidence_clusters": low_evidence_clusters,
        "clusters_by_type": {
            "barriers": barriers_count,
            "ideas": ideas_count,
            "signals": signals_count,
            "signals_platform": signals_platform_count
        }
    }
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É reports –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    Path("reports").mkdir(exist_ok=True, parents=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    Path(out).write_text(json.dumps(out_data, ensure_ascii=False, indent=2), encoding="utf-8")
    
    logger.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {out}")
    logger.info(f"  –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {clusters_count}")
    logger.info(f"  –°—Ä–µ–¥–Ω–µ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä: {avg_mentions:.2f}")
    logger.info(f"  –í—Å–µ–≥–æ —Ü–∏—Ç–∞—Ç: {total_quotes}")
    logger.info(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ —Ü–∏—Ç–∞—Ç–∞–º–∏: {out_data['quotes_coverage']:.2%}")
    
    return out_data


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Stage 7"""
    logger.info("üöÄ Stage 7: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
    
    try:
        quality_metrics = compute_quality()
        logger.info("‚úÖ Stage 7 –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        return quality_metrics
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Stage 7: {e}")
        raise


if __name__ == "__main__":
    main()
