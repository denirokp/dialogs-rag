#!/usr/bin/env python3
"""
Stage 1.5: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–∏–∞–ª–æ–≥–æ–≤
–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º —Å–∫–æ—Ä–∏–Ω–≥–æ–º
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Tuple
from tqdm import tqdm

import sys
sys.path.append(str(Path(__file__).parent.parent))

from filters.regexes import DELIVERY_ANY, PLATFORM_NOISE, BARRIER_MARK, IDEA_MARK, YESNO
from utils.turns import split_turns
from models.validation import DeliveryDetection

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MIN_DURATION_SEC = 180


def extract_duration(dialog: Dict[str, Any]) -> int:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
    duration_str = dialog.get("duration", "")
    if not duration_str:
        return 0
    
    # –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–æ—Ä–º–∞—Ç–∞ "MM:SS" –∏–ª–∏ "HH:MM:SS"
    try:
        parts = duration_str.split(":")
        if len(parts) == 2:  # MM:SS
            minutes, seconds = map(int, parts)
            return minutes * 60 + seconds
        elif len(parts) == 3:  # HH:MM:SS
            hours, minutes, seconds = map(int, parts)
            return hours * 3600 + minutes * 60 + seconds
    except (ValueError, IndexError):
        pass
    
    return 0


def is_valid_delivery_dialog(text: str, turns: list, duration_sec: int) -> Tuple[bool, str]:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∞ –æ –¥–æ—Å—Ç–∞–≤–∫–µ
    """
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    if duration_sec and duration_sec < MIN_DURATION_SEC:
        return False, "short_call"
    
    # 2. –ê–Ω–∞–ª–∏–∑ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —É –∫–ª–∏–µ–Ω—Ç–∞
    client_kw_hits = []
    client_markers = []
    first_initiator = "unknown"
    delivered_seen = False

    for i, t in enumerate(turns):
        sp, tx = t["speaker"], t["text"]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
        if sp == "–æ–ø–µ—Ä–∞—Ç–æ—Ä" and not delivered_seen and DELIVERY_ANY.search(tx):
            first_initiator = "operator"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —É –∫–ª–∏–µ–Ω—Ç–∞
        if sp == "–∫–ª–∏–µ–Ω—Ç" and DELIVERY_ANY.search(tx):
            if not delivered_seen:
                first_initiator = "client"
                delivered_seen = True
            client_kw_hits.append((i, DELIVERY_ANY.search(tx).group(0)))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Ä–∫–µ—Ä–æ–≤ —É –∫–ª–∏–µ–Ω—Ç–∞
        if sp == "–∫–ª–∏–µ–Ω—Ç":
            barrier_match = BARRIER_MARK.search(tx)
            idea_match = IDEA_MARK.search(tx)
            if barrier_match:
                client_markers.append((i, barrier_match.group(0)))
            elif idea_match:
                client_markers.append((i, idea_match.group(0)))

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —É –∫–ª–∏–µ–Ω—Ç–∞
    if not client_kw_hits:
        return False, "no_client_kw"
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–∞—Ä–∫–µ—Ä–æ–≤ —É –∫–ª–∏–µ–Ω—Ç–∞
    if not client_markers:
        return False, "no_marker"

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–≥–æ —à—É–º–∞ –±–µ–∑ –¥–æ—Å—Ç–∞–≤–æ—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ —É –∫–ª–∏–µ–Ω—Ç–∞
    if PLATFORM_NOISE.search(text) and not client_kw_hits:
        return False, "platform_noise"

    # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ—Å–ª–æ–∂–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
    if first_initiator == "operator":
        client_only_yesno = all(YESNO.match(t["text"]) for t in turns if t["speaker"] == "–∫–ª–∏–µ–Ω—Ç")
        if client_only_yesno:
            return False, "operator_initiated_yesno"

    return True, "ok"


def analyze_dialog(dialog: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º —Å–∫–æ—Ä–∏–Ω–≥–æ–º
    """
    dialog_id = str(dialog.get("ID –∑–≤–æ–Ω–∫–∞", "unknown"))
    text = dialog.get("–¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏", "")
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    duration_sec = extract_duration(dialog)
    
    # –†–∞–∑–±–æ—Ä –¥–∏–∞–ª–æ–≥–∞ –Ω–∞ —Ä–µ–ø–ª–∏–∫–∏
    turns = split_turns(text)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
    is_valid, reason = is_valid_delivery_dialog(text, turns, duration_sec)
    
    # –ü–æ–¥—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤
    if is_valid:
        client_kw_hits = []
        client_markers = []
        first_initiator = "unknown"
        delivered_seen = False

        for i, t in enumerate(turns):
            sp, tx = t["speaker"], t["text"]
            
            if sp == "–æ–ø–µ—Ä–∞—Ç–æ—Ä" and not delivered_seen and DELIVERY_ANY.search(tx):
                first_initiator = "operator"
            
            if sp == "–∫–ª–∏–µ–Ω—Ç" and DELIVERY_ANY.search(tx):
                if not delivered_seen:
                    first_initiator = "client"
                    delivered_seen = True
                client_kw_hits.append((i, DELIVERY_ANY.search(tx).group(0)))
            
            if sp == "–∫–ª–∏–µ–Ω—Ç":
                barrier_match = BARRIER_MARK.search(tx)
                idea_match = IDEA_MARK.search(tx)
                if barrier_match:
                    client_markers.append((i, barrier_match.group(0)))
                elif idea_match:
                    client_markers.append((i, idea_match.group(0)))

        # –ü–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        client_kw_unique = set(match[1].lower() for match in client_kw_hits)
        
        return {
            "dialog_id": dialog_id,
            "valid_sample": True,
            "reason": reason,
            "duration_sec": duration_sec,
            "first_delivery_initiator": first_initiator,
            "client_kw_hits_total": len(client_kw_hits),
            "client_kw_unique": list(client_kw_unique),
            "client_marker_hits_total": len(client_markers),
            "client_kw_examples": [match[1] for match in client_kw_hits[:3]],
            "client_marker_examples": [match[1] for match in client_markers[:3]],
        }
    else:
        return {
            "dialog_id": dialog_id,
            "valid_sample": False,
            "reason": reason,
            "duration_sec": duration_sec,
            "first_delivery_initiator": "unknown",
            "client_kw_hits_total": 0,
            "client_kw_unique": [],
            "client_marker_hits_total": 0,
            "client_kw_examples": [],
            "client_marker_examples": [],
        }


def load_delivery_detections() -> List[DeliveryDetection]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–æ—Å—Ç–∞–≤–∫–∏"""
    delivery_file = Path("artifacts/stage1_delivery.jsonl")
    
    if not delivery_file.exists():
        logger.error(f"‚ùå –§–∞–π–ª {delivery_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Stage 1 —Å–Ω–∞—á–∞–ª–∞.")
        return []
    
    detections = []
    with open(delivery_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line.strip())
                detection = DeliveryDetection(**data)
                detections.append(detection)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
                continue
    
    return detections


def load_dialogs() -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤ –∏–∑ Excel"""
    import pandas as pd
    
    dialogs_file = Path("data/dialogs.xlsx")
    if not dialogs_file.exists():
        logger.error(f"‚ùå –§–∞–π–ª {dialogs_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return []
    
    try:
        df = pd.read_excel(dialogs_file)
        dialogs = df.to_dict('records')
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
        return dialogs
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤: {e}")
        return []


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Stage 1.5"""
    logger.info("üöÄ Stage 1.5: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–∏–∞–ª–æ–≥–æ–≤")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Stage 1
    logger.info("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Stage 1...")
    detections = load_delivery_detections()
    
    if not detections:
        logger.error("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Stage 1")
        return
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π
    delivery_dialog_ids = {d.dialog_id for d in detections if d.delivery_discussed}
    logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(delivery_dialog_ids)} –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤
    logger.info("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ data/dialogs.xlsx...")
    dialogs = load_dialogs()
    
    if not dialogs:
        logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤")
        return
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π
    delivery_dialogs = [d for d in dialogs if str(d.get("ID –∑–≤–æ–Ω–∫–∞", "")) in delivery_dialog_ids]
    logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(delivery_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π")
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    if len(delivery_dialogs) == 0:
        logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π. –ü—Ä–æ–≤–µ—Ä—è–µ–º ID...")
        sample_dialog_ids = [str(d.get("ID –∑–≤–æ–Ω–∫–∞", "")) for d in dialogs[:3]]
        sample_delivery_ids = list(delivery_dialog_ids)[:3]
        logger.warning(f"  –ü—Ä–∏–º–µ—Ä—ã ID –∏–∑ Excel: {sample_dialog_ids}")
        logger.warning(f"  –ü—Ä–∏–º–µ—Ä—ã ID –∏–∑ Stage 1: {sample_delivery_ids}")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤
    logger.info("üîç –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤...")
    results = []
    
    for dialog in tqdm(delivery_dialogs, desc="–ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤"):
        result = analyze_dialog(dialog)
        results.append(result)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    valid_count = sum(1 for r in results if r["valid_sample"])
    invalid_count = len(results) - valid_count
    
    logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
    logger.info(f"  –í–∞–ª–∏–¥–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {valid_count}")
    logger.info(f"  –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {invalid_count}")
    if results:
        logger.info(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö: {100.0 * valid_count / len(results):.1f}%")
    else:
        logger.info(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö: 0.0%")
    
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
    reasons = {}
    for result in results:
        if not result["valid_sample"]:
            reason = result["reason"]
            reasons[reason] = reasons.get(reason, 0) + 1
    
    if reasons:
        logger.info(f"üìä –ü—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:")
        for reason, count in sorted(reasons.items(), key=lambda x: x[1], reverse=True):
            logger.info(f"  {reason}: {count}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = Path("artifacts/stage1_5_sampling.jsonl")
    output_file.parent.mkdir(exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
    logger.info("‚úÖ Stage 1.5 –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    main()