#!/usr/bin/env python3
"""
Pipeline Manager - –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–º–∏ —ç—Ç–∞–ø–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
"""

import sys
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum

# –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É pipeline –≤ –ø—É—Ç—å
pipeline_path = str(Path(__file__).parent / "pipeline")
if pipeline_path not in sys.path:
    sys.path.append(pipeline_path)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/pipeline_manager.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π pipeline
try:
    from stage1_detect_delivery import main as stage1_main
    from stage1_5_sample_filter import main as stage1_5_main
    from stage2_extract_entities import main as stage2_main
    from stage3_normalize import main as stage3_main
    from stage4_cluster import main as stage4_main
    from stage5_aggregate import main as stage5_main
    from stage6_report import main as stage6_main
    from stage7_quality import main as stage7_main
except ImportError as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π pipeline: {e}")
    logger.error("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã pipeline –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ pipeline/")
    sys.exit(1)

class StageStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã —ç—Ç–∞–ø–æ–≤"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class StageResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–∞"""
    stage_id: str
    stage_name: str
    status: StageStatus
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    error_message: Optional[str] = None
    output_files: List[str] = None
    metrics: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.output_files is None:
            self.output_files = []
        if self.metrics is None:
            self.metrics = {}

@dataclass
class PipelineConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pipeline"""
    input_file: str = "data/dialogs.xlsx"
    output_dir: str = "artifacts"
    reports_dir: str = "reports"
    logs_dir: str = "logs"
    batch_size: int = 100
    max_retries: int = 3
    parallel_execution: bool = False
    skip_failed_stages: bool = False
    cleanup_intermediate: bool = False

class PipelineManager:
    """–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä pipeline"""
    
    def __init__(self, config: PipelineConfig = None):
        self.config = config or PipelineConfig()
        self.stages = self._initialize_stages()
        self.results: Dict[str, StageResult] = {}
        self.pipeline_start_time: Optional[datetime] = None
        self.pipeline_end_time: Optional[datetime] = None
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self._create_directories()
    
    def _initialize_stages(self) -> Dict[str, Dict[str, Any]]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç—Ç–∞–ø–æ–≤ pipeline"""
        return {
            "1": {
                "name": "–î–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏",
                "function": stage1_main,
                "dependencies": [],
                "output_files": ["stage1_delivery.jsonl"],
                "description": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤, –≥–¥–µ –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è –¥–æ—Å—Ç–∞–≤–∫–∞"
            },
            "1.5": {
                "name": "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤",
                "function": stage1_5_main,
                "dependencies": ["1"],
                "output_files": ["stage1_5_sampling.jsonl"],
                "description": "–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º —Å–∫–æ—Ä–∏–Ω–≥–æ–º"
            },
            "2": {
                "name": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π", 
                "function": stage2_main,
                "dependencies": ["1"],
                "output_files": ["stage2_extracted.jsonl"],
                "description": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞—Ä—å–µ—Ä–æ–≤, –∏–¥–µ–π –∏ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤"
            },
            "3": {
                "name": "–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫",
                "function": stage3_main,
                "dependencies": ["2"],
                "output_files": ["stage3_normalized.jsonl"],
                "description": "–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∫ –µ–¥–∏–Ω–æ–º—É –≤–∏–¥—É"
            },
            "4": {
                "name": "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è",
                "function": stage4_main,
                "dependencies": ["3"],
                "output_files": ["stage4_clusters.json"],
                "description": "–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã"
            },
            "5": {
                "name": "–ê–≥—Ä–µ–≥–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫",
                "function": stage5_main,
                "dependencies": ["4"],
                "output_files": ["aggregate_results.json", "barriers.csv", "ideas.csv", "signals.csv"],
                "description": "–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º"
            },
            "6": {
                "name": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤",
                "function": stage6_main,
                "dependencies": ["5"],
                "output_files": ["report.md", "report.xlsx", "appendix_ids.md"],
                "description": "–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"
            },
            "7": {
                "name": "–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞",
                "function": stage7_main,
                "dependencies": ["6"],
                "output_files": ["quality.json"],
                "description": "–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞"
            }
        }
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        directories = [
            self.config.output_dir,
            self.config.reports_dir,
            self.config.logs_dir
        ]
        
        for directory in directories:
            Path(directory).mkdir(exist_ok=True)
            logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {directory}")
    
    def get_stage_status(self, stage_id: str) -> StageStatus:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —ç—Ç–∞–ø–∞"""
        if stage_id not in self.results:
            return StageStatus.PENDING
        return self.results[stage_id].status
    
    def can_run_stage(self, stage_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–ø—É—Å–∫–∞ —ç—Ç–∞–ø–∞"""
        if stage_id not in self.stages:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        for dep in self.stages[stage_id]["dependencies"]:
            if self.get_stage_status(dep) != StageStatus.COMPLETED:
                return False
        
        return True
    
    def run_stage(self, stage_id: str) -> StageResult:
        """–ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç—Ç–∞–ø–∞"""
        if stage_id not in self.stages:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —ç—Ç–∞–ø: {stage_id}")
        
        stage_info = self.stages[stage_id]
        stage_name = stage_info["name"]
        
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —ç—Ç–∞–ø–∞ {stage_id}: {stage_name}")
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = StageResult(
            stage_id=stage_id,
            stage_name=stage_name,
            status=StageStatus.RUNNING,
            start_time=datetime.now()
        )
        
        self.results[stage_id] = result
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            if not self.can_run_stage(stage_id):
                missing_deps = [
                    dep for dep in stage_info["dependencies"]
                    if self.get_stage_status(dep) != StageStatus.COMPLETED
                ]
                raise ValueError(f"–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {missing_deps}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —ç—Ç–∞–ø
            stage_info["function"]()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result.status = StageStatus.COMPLETED
            result.end_time = datetime.now()
            result.duration_seconds = (result.end_time - result.start_time).total_seconds()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
            self._check_output_files(stage_id, result)
            
            logger.info(f"‚úÖ –≠—Ç–∞–ø {stage_id} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {result.duration_seconds:.1f}—Å")
            
        except Exception as e:
            result.status = StageStatus.FAILED
            result.end_time = datetime.now()
            result.duration_seconds = (result.end_time - result.start_time).total_seconds()
            result.error_message = str(e)
            
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —ç—Ç–∞–ø–µ {stage_id}: {e}")
            
            if not self.config.skip_failed_stages:
                raise
        
        return result
    
    def _check_output_files(self, stage_id: str, result: StageResult):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —ç—Ç–∞–ø–∞"""
        expected_files = self.stages[stage_id]["output_files"]
        
        for filename in expected_files:
            file_path = Path(self.config.output_dir) / filename
            if file_path.exists():
                result.output_files.append(str(file_path))
            else:
                logger.warning(f"‚ö†Ô∏è –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    
    def run_pipeline(self, stage_ids: List[str] = None) -> Dict[str, StageResult]:
        """–ó–∞–ø—É—Å–∫ pipeline"""
        if stage_ids is None:
            stage_ids = list(self.stages.keys())
        
        logger.info("üîç Dialogs RAG - Pipeline Manager")
        logger.info("=" * 60)
        
        self.pipeline_start_time = datetime.now()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        if not self._check_dependencies():
            raise RuntimeError("–ù–µ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —ç—Ç–∞–ø—ã
        for stage_id in stage_ids:
            try:
                self.run_stage(stage_id)
            except Exception as e:
                logger.error(f"‚ùå Pipeline –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —ç—Ç–∞–ø–µ {stage_id}: {e}")
                if not self.config.skip_failed_stages:
                    break
        
        self.pipeline_end_time = datetime.now()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._log_pipeline_summary()
        
        return self.results
    
    def _check_dependencies(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
        
        try:
            import pandas
            import openpyxl
            import tqdm
            import tenacity
            import sklearn
            import numpy
            import openai
            import chromadb
            import sentence_transformers
            logger.info("‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            return True
        except ImportError as e:
            logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: {e}")
            logger.error("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements.txt")
            return False
    
    def _log_pipeline_summary(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        total_stages = len(self.results)
        completed_stages = sum(1 for r in self.results.values() if r.status == StageStatus.COMPLETED)
        failed_stages = sum(1 for r in self.results.values() if r.status == StageStatus.FAILED)
        
        total_duration = (self.pipeline_end_time - self.pipeline_start_time).total_seconds()
        
        logger.info("=" * 60)
        logger.info(f"üìä Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω: {completed_stages}/{total_stages} —ç—Ç–∞–ø–æ–≤ —É—Å–ø–µ—à–Ω–æ")
        logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_duration:.1f} —Å–µ–∫")
        
        if failed_stages > 0:
            logger.error(f"‚ùå –û—à–∏–±–æ–∫: {failed_stages}")
            for stage_id, result in self.results.items():
                if result.status == StageStatus.FAILED:
                    logger.error(f"  - –≠—Ç–∞–ø {stage_id}: {result.error_message}")
        else:
            logger.info("üéâ –í—Å–µ —ç—Ç–∞–ø—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            logger.info("üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–∞—Ö artifacts/ –∏ reports/")
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ pipeline"""
        return {
            "pipeline_start_time": self.pipeline_start_time.isoformat() if self.pipeline_start_time else None,
            "pipeline_end_time": self.pipeline_end_time.isoformat() if self.pipeline_end_time else None,
            "total_duration_seconds": (self.pipeline_end_time - self.pipeline_start_time).total_seconds() if self.pipeline_start_time and self.pipeline_end_time else None,
            "stages": {
                stage_id: {
                    "name": result.stage_name,
                    "status": result.status.value,
                    "duration_seconds": result.duration_seconds,
                    "error_message": result.error_message,
                    "output_files": result.output_files
                }
                for stage_id, result in self.results.items()
            }
        }
    
    def save_pipeline_state(self, filepath: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è pipeline"""
        if filepath is None:
            filepath = Path(self.config.logs_dir) / f"pipeline_state_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        state = {
            "config": asdict(self.config),
            "pipeline_status": self.get_pipeline_status(),
            "timestamp": datetime.now().isoformat()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ pipeline —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filepath}")
    
    def load_pipeline_state(self, filepath: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è pipeline"""
        with open(filepath, 'r', encoding='utf-8') as f:
            state = json.load(f)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config = PipelineConfig(**state["config"])
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–æ–≤
        for stage_id, stage_data in state["pipeline_status"]["stages"].items():
            result = StageResult(
                stage_id=stage_id,
                stage_name=stage_data["name"],
                status=StageStatus(stage_data["status"]),
                duration_seconds=stage_data["duration_seconds"],
                error_message=stage_data["error_message"],
                output_files=stage_data["output_files"]
            )
            self.results[stage_id] = result
        
        logger.info(f"üìÇ –°–æ—Å—Ç–æ—è–Ω–∏–µ pipeline –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ {filepath}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Pipeline Manager –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤")
    parser.add_argument(
        "--stages",
        nargs="+",
        choices=list("1234567") + ["1.5"] + ["all"],
        default=["all"],
        help="–≠—Ç–∞–ø—ã –¥–ª—è –∑–∞–ø—É—Å–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: all)"
    )
    parser.add_argument(
        "--from", 
        type=str,
        choices=list("123456") + ["1.5"],
        help="–ù–∞—á–∞—Ç—å —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞"
    )
    parser.add_argument(
        "--to", 
        type=str,
        choices=list("123456") + ["1.5"],
        help="–ó–∞–≤–µ—Ä—à–∏—Ç—å –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ"
    )
    parser.add_argument(
        "--config",
        type=str,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
    )
    parser.add_argument(
        "--skip-failed",
        action="store_true",
        help="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç—Ç–∞–ø–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞
    all_stages = ["1", "1.5", "2", "3", "4", "5", "6", "7"]
    
    if "all" in args.stages:
        stages = all_stages
    else:
        stages = args.stages
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É
    if hasattr(args, 'from_') and args.from_:
        from_idx = all_stages.index(args.from_)
        stages = [s for s in stages if all_stages.index(s) >= from_idx]
    
    if hasattr(args, 'to') and args.to:
        to_idx = all_stages.index(args.to)
        stages = [s for s in stages if all_stages.index(s) <= to_idx]
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = PipelineConfig()
    if args.skip_failed:
        config.skip_failed_stages = True
    
    # –ó–∞–ø—É—Å–∫ pipeline
    manager = PipelineManager(config)
    success = manager.run_pipeline(stages)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    manager.save_pipeline_state()
    
    if all(result.status == StageStatus.COMPLETED for result in success.values()):
        logger.info("üéØ Pipeline –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        sys.exit(0)
    else:
        logger.error("üí• Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏")
        sys.exit(1)

if __name__ == "__main__":
    main()
